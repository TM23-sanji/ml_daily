{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport os\nimport urllib\n\ndef download_and_load_file(file_path, url):\n    if not os.path.exists(file_path):\n        with urllib.request.urlopen(url) as response:\n            text_data = response.read().decode('utf-8')\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(text_data)\n    else:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            text_data = file.read()\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n    return data\n\nfile_path = 'instruction-data.json'\nurl = (\n     \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n)\ndata = download_and_load_file(file_path, url)\nprint('Number of entries:', len(data))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:03.648302Z","iopub.execute_input":"2025-10-15T21:16:03.648585Z","iopub.status.idle":"2025-10-15T21:16:03.657128Z","shell.execute_reply.started":"2025-10-15T21:16:03.648563Z","shell.execute_reply":"2025-10-15T21:16:03.656513Z"}},"outputs":[{"name":"stdout","text":"Number of entries: 1100\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"print('Example entry:\\n', data[50])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:05.457655Z","iopub.execute_input":"2025-10-15T21:16:05.458406Z","iopub.status.idle":"2025-10-15T21:16:05.462407Z","shell.execute_reply.started":"2025-10-15T21:16:05.458380Z","shell.execute_reply":"2025-10-15T21:16:05.461639Z"}},"outputs":[{"name":"stdout","text":"Example entry:\n {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"print('Another example entry:\\n', data[999])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:06.215942Z","iopub.execute_input":"2025-10-15T21:16:06.216189Z","iopub.status.idle":"2025-10-15T21:16:06.220556Z","shell.execute_reply.started":"2025-10-15T21:16:06.216173Z","shell.execute_reply":"2025-10-15T21:16:06.219790Z"}},"outputs":[{"name":"stdout","text":"Another example entry:\n {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"def format_input(entry):\n    \n    instruction_text = (\n        f\"Below is an instruction that describes a task. \"\n        f\"Write a response that appropriately completes the request.\"\n        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n    )\n    input_text = (\n        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n    )\n    return instruction_text + input_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:06.409886Z","iopub.execute_input":"2025-10-15T21:16:06.410549Z","iopub.status.idle":"2025-10-15T21:16:06.414436Z","shell.execute_reply.started":"2025-10-15T21:16:06.410527Z","shell.execute_reply":"2025-10-15T21:16:06.413648Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"model_input = format_input(data[50])\ndesired_response = f'\\n\\n### Response:\\n{data[50][\"output\"]}'\nprint(model_input + desired_response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:06.597592Z","iopub.execute_input":"2025-10-15T21:16:06.597876Z","iopub.status.idle":"2025-10-15T21:16:06.602061Z","shell.execute_reply.started":"2025-10-15T21:16:06.597856Z","shell.execute_reply":"2025-10-15T21:16:06.601432Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nIdentify the correct spelling of the following word.\n\n### Input:\nOcassion\n\n### Response:\nThe correct spelling is 'Occasion.'\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"model_input = format_input(data[999])\ndesired_response = f'\\n\\n### Response:\\n{data[999][\"output\"]}'\nprint(model_input + desired_response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:06.813557Z","iopub.execute_input":"2025-10-15T21:16:06.814220Z","iopub.status.idle":"2025-10-15T21:16:06.818517Z","shell.execute_reply.started":"2025-10-15T21:16:06.814197Z","shell.execute_reply":"2025-10-15T21:16:06.817773Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nWhat is an antonym of 'complicated'?\n\n### Response:\nAn antonym of 'complicated' is 'simple'.\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"train_portion = int(len(data) * 0.85)\ntest_portion = int(len(data) *  0.1)\nval_portion = len(data) - train_portion - test_portion\n\ntrain_data = data[:train_portion]\ntest_data  = data[train_portion:train_portion + test_portion]\nval_data = data[train_portion + test_portion:]\n\nprint(\"Training set length:\", len(train_data))\nprint(\"Validation set length:\", len(val_data))\nprint(\"Test set length:\", len(test_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:07.012979Z","iopub.execute_input":"2025-10-15T21:16:07.013628Z","iopub.status.idle":"2025-10-15T21:16:07.018636Z","shell.execute_reply.started":"2025-10-15T21:16:07.013609Z","shell.execute_reply":"2025-10-15T21:16:07.017862Z"}},"outputs":[{"name":"stdout","text":"Training set length: 935\nValidation set length: 55\nTest set length: 110\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass InstructionDataset(Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n        self.encoded_texts = []\n        for entry in data:\n            instruction_plus_input = format_input(entry)\n            response_text = f'\\n\\n### Response:\\n{entry[\"output\"]}'\n            full_text = instruction_plus_input + response_text\n            self.encoded_texts.append(\n                tokenizer.encode(full_text)\n            )\n            \n    def __getitem__(self, index):\n        return self.encoded_texts[index]\n        \n    def __len__(self):\n        return len(self.data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:07.182972Z","iopub.execute_input":"2025-10-15T21:16:07.183240Z","iopub.status.idle":"2025-10-15T21:16:07.188561Z","shell.execute_reply.started":"2025-10-15T21:16:07.183219Z","shell.execute_reply":"2025-10-15T21:16:07.187686Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"import tiktoken\ntokenizer = tiktoken.get_encoding('gpt2')\nprint(tokenizer.encode('<|endoftext|>', allowed_special={'<|endoftext|>'}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:07.368943Z","iopub.execute_input":"2025-10-15T21:16:07.369613Z","iopub.status.idle":"2025-10-15T21:16:07.373697Z","shell.execute_reply.started":"2025-10-15T21:16:07.369580Z","shell.execute_reply":"2025-10-15T21:16:07.372997Z"}},"outputs":[{"name":"stdout","text":"[50256]\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"def custom_collate_draft_1(\n    batch, pad_token_id=50256, device='cpu'\n):\n    batch_max_length = max(len(item) + 1 for item in batch)\n    inputs_lst = []\n    for item in batch:\n        new_item = item.copy()\n        new_item += [pad_token_id]\n        padded = (\n            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n        )\n        inputs = torch.tensor(padded[:-1])\n        inputs_lst.append(inputs)\n    inputs_tensor = torch.stack(inputs_lst).to(device)\n    return inputs_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:07.540858Z","iopub.execute_input":"2025-10-15T21:16:07.541287Z","iopub.status.idle":"2025-10-15T21:16:07.546165Z","shell.execute_reply.started":"2025-10-15T21:16:07.541266Z","shell.execute_reply":"2025-10-15T21:16:07.545228Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"inputs_1 = [0, 1, 2, 3, 4]\ninputs_2 = [5, 6]\ninputs_3 = [7, 8, 9]\nbatch = (\n    inputs_1,\n    inputs_2,\n    inputs_3\n )\nprint(custom_collate_draft_1(batch))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:07.743180Z","iopub.execute_input":"2025-10-15T21:16:07.743436Z","iopub.status.idle":"2025-10-15T21:16:07.749206Z","shell.execute_reply.started":"2025-10-15T21:16:07.743416Z","shell.execute_reply":"2025-10-15T21:16:07.748558Z"}},"outputs":[{"name":"stdout","text":"tensor([[    0,     1,     2,     3,     4],\n        [    5,     6, 50256, 50256, 50256],\n        [    7,     8,     9, 50256, 50256]])\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"def custom_collate_draft_2(\n    batch,\n    pad_token_id=20526,\n    device='cpu'\n):\n    batch_max_length = max(len(item)+1 for item in batch)\n    inputs_lst, targets_lst = [], []\n    \n    for item in batch:\n        new_item = item.copy()\n        new_item += [pad_token_id]\n        padded = (\n            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n        )\n        inputs = torch.tensor(padded[:-1])\n        targets = torch.tensor(padded[1:])\n        inputs_lst.append(inputs)\n        targets_lst.append(targets)\n        \n    inputs_tensor = torch.stack(inputs_lst).to(device)\n    targets_tensor = torch.stack(targets_lst).to(device)\n    return inputs_tensor, targets_tensor\n    \ninputs, targets = custom_collate_draft_2(batch)\nprint(inputs)\nprint(targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:07.923197Z","iopub.execute_input":"2025-10-15T21:16:07.923442Z","iopub.status.idle":"2025-10-15T21:16:07.930847Z","shell.execute_reply.started":"2025-10-15T21:16:07.923422Z","shell.execute_reply":"2025-10-15T21:16:07.930227Z"}},"outputs":[{"name":"stdout","text":"tensor([[    0,     1,     2,     3,     4],\n        [    5,     6, 20526, 20526, 20526],\n        [    7,     8,     9, 20526, 20526]])\ntensor([[    1,     2,     3,     4, 20526],\n        [    6, 20526, 20526, 20526, 20526],\n        [    8,     9, 20526, 20526, 20526]])\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"def custom_collate_fn(\n    batch,\n    pad_token_id=50256,\n    ignore_index=-100,\n    allowed_max_length=None,\n    device='cpu'\n):\n    batch_max_length = max(len(item)+1 for item in batch)\n    inputs_lst, targets_lst = [], []\n    for item in batch:\n        new_item = item.copy()\n        padded = (\n            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n        )\n        inputs = torch.tensor(padded[:-1])\n        targets = torch.tensor(padded[1:])\n        \n        mask = targets == pad_token_id\n        indices = torch.nonzero(mask).squeeze()\n        if indices.numel() > 1:\n            targets[indices[1:]] = ignore_index\n        if allowed_max_length is not None:\n            inputs = inputs[:allowed_max_length]\n            targets = targets[:allowed_max_length]\n        inputs_lst.append(inputs)\n        targets_lst.append(targets)\n    inputs_tensor = torch.stack(inputs_lst).to(device)\n    targets_tensor = torch.stack(targets_lst).to(device)\n    return inputs_tensor, targets_tensor            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:08.102527Z","iopub.execute_input":"2025-10-15T21:16:08.103216Z","iopub.status.idle":"2025-10-15T21:16:08.108767Z","shell.execute_reply.started":"2025-10-15T21:16:08.103193Z","shell.execute_reply":"2025-10-15T21:16:08.108081Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"inputs, targets = custom_collate_fn(batch)\nprint(inputs)\nprint(targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:08.296970Z","iopub.execute_input":"2025-10-15T21:16:08.297427Z","iopub.status.idle":"2025-10-15T21:16:08.303092Z","shell.execute_reply.started":"2025-10-15T21:16:08.297407Z","shell.execute_reply":"2025-10-15T21:16:08.302480Z"}},"outputs":[{"name":"stdout","text":"tensor([[    0,     1,     2,     3,     4],\n        [    5,     6, 50256, 50256, 50256],\n        [    7,     8,     9, 50256, 50256]])\ntensor([[    1,     2,     3,     4, 50256],\n        [    6, 50256,  -100,  -100,  -100],\n        [    8,     9, 50256,  -100,  -100]])\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"logits_1 = torch.tensor(\n    [[-1.0, 1.0],    \n     [-0.5, 1.5]]     \n)\ntargets_1 = torch.tensor([0, 1])\nloss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\nprint(loss_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:08.493529Z","iopub.execute_input":"2025-10-15T21:16:08.493902Z","iopub.status.idle":"2025-10-15T21:16:08.499713Z","shell.execute_reply.started":"2025-10-15T21:16:08.493881Z","shell.execute_reply":"2025-10-15T21:16:08.499003Z"}},"outputs":[{"name":"stdout","text":"tensor(1.1269)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"logits_2 = torch.tensor(\n    [[-1.0, 1.0],\n     [-0.5, 1.5],\n     [-0.5, 1.5]]     \n)\ntargets_2 = torch.tensor([0, 1, 1])\nloss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\nprint(loss_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:08.684159Z","iopub.execute_input":"2025-10-15T21:16:08.684713Z","iopub.status.idle":"2025-10-15T21:16:08.690328Z","shell.execute_reply.started":"2025-10-15T21:16:08.684691Z","shell.execute_reply":"2025-10-15T21:16:08.689523Z"}},"outputs":[{"name":"stdout","text":"tensor(0.7936)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"targets_3 = torch.tensor([0, 1, -100])\nloss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\nprint(loss_3)\nprint(\"loss_1 == loss_3:\", loss_1 == loss_3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:08.860095Z","iopub.execute_input":"2025-10-15T21:16:08.860670Z","iopub.status.idle":"2025-10-15T21:16:08.866920Z","shell.execute_reply.started":"2025-10-15T21:16:08.860650Z","shell.execute_reply":"2025-10-15T21:16:08.866107Z"}},"outputs":[{"name":"stdout","text":"tensor(1.1269)\nloss_1 == loss_3: tensor(True)\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('Device:', device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:30.439040Z","iopub.execute_input":"2025-10-15T21:16:30.439500Z","iopub.status.idle":"2025-10-15T21:16:30.443859Z","shell.execute_reply.started":"2025-10-15T21:16:30.439477Z","shell.execute_reply":"2025-10-15T21:16:30.443026Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"from functools import partial\n\ncustomized_collate_fn = partial(\n    custom_collate_fn,\n    device=device,\n    allowed_max_length=1024\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:31.109442Z","iopub.execute_input":"2025-10-15T21:16:31.110039Z","iopub.status.idle":"2025-10-15T21:16:31.113744Z","shell.execute_reply.started":"2025-10-15T21:16:31.110014Z","shell.execute_reply":"2025-10-15T21:16:31.113163Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nnum_workers = 0\nbatch_size = 8\n\ntorch.manual_seed(123)\n\ntrain_dataset = InstructionDataset(train_data, tokenizer)\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size = batch_size,\n    collate_fn = customized_collate_fn,\n    shuffle = True,\n    drop_last = True,\n    num_workers = num_workers\n)\n\nval_dataset = InstructionDataset(val_data, tokenizer)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size = batch_size,\n    collate_fn = customized_collate_fn,\n    shuffle = True,\n    drop_last = True,\n    num_workers = num_workers\n)\n\ntest_dataset = InstructionDataset(test_data, tokenizer)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size = batch_size,\n    collate_fn = customized_collate_fn,\n    shuffle = True,\n    drop_last = True,\n    num_workers = num_workers\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:31.651285Z","iopub.execute_input":"2025-10-15T21:16:31.651834Z","iopub.status.idle":"2025-10-15T21:16:31.694860Z","shell.execute_reply.started":"2025-10-15T21:16:31.651811Z","shell.execute_reply":"2025-10-15T21:16:31.694303Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"print(\"Train loader:\")\nfor inputs, targets in train_loader:\n   print(inputs.shape, targets.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:52.933077Z","iopub.execute_input":"2025-10-15T21:16:52.933331Z","iopub.status.idle":"2025-10-15T21:16:53.037427Z","shell.execute_reply.started":"2025-10-15T21:16:52.933311Z","shell.execute_reply":"2025-10-15T21:16:53.036375Z"}},"outputs":[{"name":"stdout","text":"Train loader:\ntorch.Size([8, 61]) torch.Size([8, 61])\ntorch.Size([8, 76]) torch.Size([8, 76])\ntorch.Size([8, 73]) torch.Size([8, 73])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 65]) torch.Size([8, 65])\ntorch.Size([8, 72]) torch.Size([8, 72])\ntorch.Size([8, 80]) torch.Size([8, 80])\ntorch.Size([8, 67]) torch.Size([8, 67])\ntorch.Size([8, 62]) torch.Size([8, 62])\ntorch.Size([8, 75]) torch.Size([8, 75])\ntorch.Size([8, 62]) torch.Size([8, 62])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 67]) torch.Size([8, 67])\ntorch.Size([8, 77]) torch.Size([8, 77])\ntorch.Size([8, 69]) torch.Size([8, 69])\ntorch.Size([8, 79]) torch.Size([8, 79])\ntorch.Size([8, 71]) torch.Size([8, 71])\ntorch.Size([8, 66]) torch.Size([8, 66])\ntorch.Size([8, 83]) torch.Size([8, 83])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 80]) torch.Size([8, 80])\ntorch.Size([8, 71]) torch.Size([8, 71])\ntorch.Size([8, 69]) torch.Size([8, 69])\ntorch.Size([8, 65]) torch.Size([8, 65])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 60]) torch.Size([8, 60])\ntorch.Size([8, 59]) torch.Size([8, 59])\ntorch.Size([8, 69]) torch.Size([8, 69])\ntorch.Size([8, 63]) torch.Size([8, 63])\ntorch.Size([8, 65]) torch.Size([8, 65])\ntorch.Size([8, 76]) torch.Size([8, 76])\ntorch.Size([8, 66]) torch.Size([8, 66])\ntorch.Size([8, 71]) torch.Size([8, 71])\ntorch.Size([8, 91]) torch.Size([8, 91])\ntorch.Size([8, 65]) torch.Size([8, 65])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 67]) torch.Size([8, 67])\ntorch.Size([8, 66]) torch.Size([8, 66])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 65]) torch.Size([8, 65])\ntorch.Size([8, 75]) torch.Size([8, 75])\ntorch.Size([8, 89]) torch.Size([8, 89])\ntorch.Size([8, 59]) torch.Size([8, 59])\ntorch.Size([8, 88]) torch.Size([8, 88])\ntorch.Size([8, 83]) torch.Size([8, 83])\ntorch.Size([8, 83]) torch.Size([8, 83])\ntorch.Size([8, 70]) torch.Size([8, 70])\ntorch.Size([8, 65]) torch.Size([8, 65])\ntorch.Size([8, 74]) torch.Size([8, 74])\ntorch.Size([8, 76]) torch.Size([8, 76])\ntorch.Size([8, 67]) torch.Size([8, 67])\ntorch.Size([8, 75]) torch.Size([8, 75])\ntorch.Size([8, 83]) torch.Size([8, 83])\ntorch.Size([8, 69]) torch.Size([8, 69])\ntorch.Size([8, 67]) torch.Size([8, 67])\ntorch.Size([8, 60]) torch.Size([8, 60])\ntorch.Size([8, 60]) torch.Size([8, 60])\ntorch.Size([8, 66]) torch.Size([8, 66])\ntorch.Size([8, 80]) torch.Size([8, 80])\ntorch.Size([8, 71]) torch.Size([8, 71])\ntorch.Size([8, 61]) torch.Size([8, 61])\ntorch.Size([8, 58]) torch.Size([8, 58])\ntorch.Size([8, 71]) torch.Size([8, 71])\ntorch.Size([8, 67]) torch.Size([8, 67])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 63]) torch.Size([8, 63])\ntorch.Size([8, 87]) torch.Size([8, 87])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 71]) torch.Size([8, 71])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 71]) torch.Size([8, 71])\ntorch.Size([8, 61]) torch.Size([8, 61])\ntorch.Size([8, 65]) torch.Size([8, 65])\ntorch.Size([8, 67]) torch.Size([8, 67])\ntorch.Size([8, 65]) torch.Size([8, 65])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 60]) torch.Size([8, 60])\ntorch.Size([8, 72]) torch.Size([8, 72])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 70]) torch.Size([8, 70])\ntorch.Size([8, 57]) torch.Size([8, 57])\ntorch.Size([8, 72]) torch.Size([8, 72])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 62]) torch.Size([8, 62])\ntorch.Size([8, 74]) torch.Size([8, 74])\ntorch.Size([8, 80]) torch.Size([8, 80])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 70]) torch.Size([8, 70])\ntorch.Size([8, 91]) torch.Size([8, 91])\ntorch.Size([8, 61]) torch.Size([8, 61])\ntorch.Size([8, 66]) torch.Size([8, 66])\ntorch.Size([8, 80]) torch.Size([8, 80])\ntorch.Size([8, 81]) torch.Size([8, 81])\ntorch.Size([8, 74]) torch.Size([8, 74])\ntorch.Size([8, 82]) torch.Size([8, 82])\ntorch.Size([8, 63]) torch.Size([8, 63])\ntorch.Size([8, 83]) torch.Size([8, 83])\ntorch.Size([8, 68]) torch.Size([8, 68])\ntorch.Size([8, 67]) torch.Size([8, 67])\ntorch.Size([8, 77]) torch.Size([8, 77])\ntorch.Size([8, 91]) torch.Size([8, 91])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 61]) torch.Size([8, 61])\ntorch.Size([8, 75]) torch.Size([8, 75])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 66]) torch.Size([8, 66])\ntorch.Size([8, 78]) torch.Size([8, 78])\ntorch.Size([8, 66]) torch.Size([8, 66])\ntorch.Size([8, 64]) torch.Size([8, 64])\ntorch.Size([8, 83]) torch.Size([8, 83])\ntorch.Size([8, 66]) torch.Size([8, 66])\ntorch.Size([8, 74]) torch.Size([8, 74])\ntorch.Size([8, 69]) torch.Size([8, 69])\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"import numpy as np\nimport tiktoken\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n#####################################\n# Chapter 2\n#####################################\n\n\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n\n        # Use a sliding window to chunk the book into overlapping sequences of max_length\n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i + 1: i + max_length + 1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]\n\n\ndef create_dataloader_v1(txt, batch_size=4, max_length=256,\n                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n    # Initialize the tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n    # Create dataset\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    # Create dataloader\n    dataloader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n\n    return dataloader\n\n\n#####################################\n# Chapter 3\n#####################################\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n\n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n\n    def forward(self, x):\n        b, num_tokens, d_in = x.shape\n\n        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n\n        # We implicitly split the matrix by adding a `num_heads` dimension\n        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n\n        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n        keys = keys.transpose(1, 2)\n        queries = queries.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n\n        # Original mask truncated to the number of tokens and converted to boolean\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n\n        # Use the mask to fill attention scores\n        attn_scores.masked_fill_(mask_bool, -torch.inf)\n\n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        # Shape: (b, num_tokens, num_heads, head_dim)\n        context_vec = (attn_weights @ values).transpose(1, 2)\n\n        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec)  # optional projection\n\n        return context_vec\n\n\n#####################################\n# Chapter 4\n#####################################\nclass LayerNorm(nn.Module):\n    def __init__(self, emb_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(emb_dim))\n        self.shift = nn.Parameter(torch.zeros(emb_dim))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n        return self.scale * norm_x + self.shift\n\n\nclass GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n            (x + 0.044715 * torch.pow(x, 3))\n        ))\n\n\nclass FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n            GELU(),\n            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.att = MultiHeadAttention(\n            d_in=cfg[\"emb_dim\"],\n            d_out=cfg[\"emb_dim\"],\n            context_length=cfg[\"context_length\"],\n            num_heads=cfg[\"n_heads\"],\n            dropout=cfg[\"drop_rate\"],\n            qkv_bias=cfg[\"qkv_bias\"])\n        self.ff = FeedForward(cfg)\n        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x):\n        # Shortcut connection for attention block\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_resid(x)\n        x = x + shortcut  # Add the original input back\n\n        # Shortcut connection for feed-forward block\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x)\n        x = self.drop_resid(x)\n        x = x + shortcut  # Add the original input back\n\n        return x\n\n\nclass GPTModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n\n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n\n        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n\n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_emb(x)\n        x = self.trf_blocks(x)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits\n\n\ndef generate_text_simple(model, idx, max_new_tokens, context_size):\n    # idx is (B, T) array of indices in the current context\n    for _ in range(max_new_tokens):\n\n        # Crop current context if it exceeds the supported context size\n        # E.g., if LLM supports only 5 tokens, and the context size is 10\n        # then only the last 5 tokens are used as context\n        idx_cond = idx[:, -context_size:]\n\n        # Get the predictions\n        with torch.no_grad():\n            logits = model(idx_cond)\n\n        # Focus only on the last time step\n        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n        logits = logits[:, -1, :]\n\n        # Get the idx of the vocab entry with the highest logits value\n        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n\n        # Append sampled index to the running sequence\n        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n\n    return idx\n\n\n#####################################\n# Chapter 5\n#####################################\ndef assign(left, right):\n    if left.shape != right.shape:\n        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n    return torch.nn.Parameter(torch.tensor(right))\n\n\ndef load_weights_into_gpt(gpt, params):\n    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n\n    for b in range(len(params[\"blocks\"])):\n        q_w, k_w, v_w = np.split(\n            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n        gpt.trf_blocks[b].att.W_query.weight = assign(\n            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n        gpt.trf_blocks[b].att.W_key.weight = assign(\n            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n        gpt.trf_blocks[b].att.W_value.weight = assign(\n            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n\n        q_b, k_b, v_b = np.split(\n            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n        gpt.trf_blocks[b].att.W_query.bias = assign(\n            gpt.trf_blocks[b].att.W_query.bias, q_b)\n        gpt.trf_blocks[b].att.W_key.bias = assign(\n            gpt.trf_blocks[b].att.W_key.bias, k_b)\n        gpt.trf_blocks[b].att.W_value.bias = assign(\n            gpt.trf_blocks[b].att.W_value.bias, v_b)\n\n        gpt.trf_blocks[b].att.out_proj.weight = assign(\n            gpt.trf_blocks[b].att.out_proj.weight,\n            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n        gpt.trf_blocks[b].att.out_proj.bias = assign(\n            gpt.trf_blocks[b].att.out_proj.bias,\n            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n\n        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n            gpt.trf_blocks[b].ff.layers[0].weight,\n            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n            gpt.trf_blocks[b].ff.layers[0].bias,\n            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n            gpt.trf_blocks[b].ff.layers[2].weight,\n            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n            gpt.trf_blocks[b].ff.layers[2].bias,\n            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n\n        gpt.trf_blocks[b].norm1.scale = assign(\n            gpt.trf_blocks[b].norm1.scale,\n            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n        gpt.trf_blocks[b].norm1.shift = assign(\n            gpt.trf_blocks[b].norm1.shift,\n            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n        gpt.trf_blocks[b].norm2.scale = assign(\n            gpt.trf_blocks[b].norm2.scale,\n            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n        gpt.trf_blocks[b].norm2.shift = assign(\n            gpt.trf_blocks[b].norm2.shift,\n            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n\n    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n\n\ndef text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n    return encoded_tensor\n\n\ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0)  # remove batch dimension\n    return tokenizer.decode(flat.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:55.910249Z","iopub.execute_input":"2025-10-15T21:16:55.910516Z","iopub.status.idle":"2025-10-15T21:16:55.943027Z","shell.execute_reply.started":"2025-10-15T21:16:55.910496Z","shell.execute_reply":"2025-10-15T21:16:55.942313Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"import os\nimport urllib.request\n\n# import requests\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tqdm import tqdm\n\n\ndef download_and_load_gpt2(model_size, models_dir):\n    # Validate model size\n    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n    if model_size not in allowed_sizes:\n        raise ValueError(f\"Model size not in {allowed_sizes}\")\n\n    # Define paths\n    model_dir = os.path.join(models_dir, model_size)\n    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n    filenames = [\n        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n        \"model.ckpt.meta\", \"vocab.bpe\"\n    ]\n\n    # Download files\n    os.makedirs(model_dir, exist_ok=True)\n    for filename in filenames:\n        file_url = os.path.join(base_url, model_size, filename)\n        backup_url = os.path.join(backup_base_url, model_size, filename)\n        file_path = os.path.join(model_dir, filename)\n        download_file(file_url, file_path, backup_url)\n\n    # Load settings and params\n    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n\n    return settings, params\n\n\ndef download_file(url, destination, backup_url=None):\n    def _attempt_download(download_url):\n        with urllib.request.urlopen(download_url) as response:\n            # Get the total file size from headers, defaulting to 0 if not present\n            file_size = int(response.headers.get(\"Content-Length\", 0))\n\n            # Check if file exists and has the same size\n            if os.path.exists(destination):\n                file_size_local = os.path.getsize(destination)\n                if file_size == file_size_local:\n                    print(f\"File already exists and is up-to-date: {destination}\")\n                    return True  # Indicate success without re-downloading\n\n            block_size = 1024  # 1 Kilobyte\n\n            # Initialize the progress bar with total file size\n            progress_bar_description = os.path.basename(download_url)\n            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n                with open(destination, \"wb\") as file:\n                    while True:\n                        chunk = response.read(block_size)\n                        if not chunk:\n                            break\n                        file.write(chunk)\n                        progress_bar.update(len(chunk))\n            return True\n\n    try:\n        if _attempt_download(url):\n            return\n    except (urllib.error.HTTPError, urllib.error.URLError):\n        if backup_url is not None:\n            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n            try:\n                if _attempt_download(backup_url):\n                    return\n            except urllib.error.HTTPError:\n                pass\n\n        # If we reach here, both attempts have failed\n        error_message = (\n            f\"Failed to download from both primary URL ({url})\"\n            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n            \"\\nCheck your internet connection or the file availability.\\n\"\n            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n        )\n        print(error_message)\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n\n\n# Alternative way using `requests`\n\"\"\"\ndef download_file(url, destination):\n    # Send a GET request to download the file in streaming mode\n    response = requests.get(url, stream=True)\n\n    # Get the total file size from headers, defaulting to 0 if not present\n    file_size = int(response.headers.get(\"content-length\", 0))\n\n    # Check if file exists and has the same size\n    if os.path.exists(destination):\n        file_size_local = os.path.getsize(destination)\n        if file_size == file_size_local:\n            print(f\"File already exists and is up-to-date: {destination}\")\n            return\n\n    # Define the block size for reading the file\n    block_size = 1024  # 1 Kilobyte\n\n    # Initialize the progress bar with total file size\n    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n        # Open the destination file in binary write mode\n        with open(destination, \"wb\") as file:\n            # Iterate over the file data in chunks\n            for chunk in response.iter_content(block_size):\n                progress_bar.update(len(chunk))  # Update progress bar\n                file.write(chunk)  # Write the chunk to the file\n\"\"\"\n\n\ndef load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n    # Initialize parameters dictionary with empty blocks for each layer\n    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n\n    # Iterate over each variable in the checkpoint\n    for name, _ in tf.train.list_variables(ckpt_path):\n        # Load the variable and remove singleton dimensions\n        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n\n        # Process the variable name to extract relevant parts\n        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n\n        # Identify the target dictionary for the variable\n        target_dict = params\n        if variable_name_parts[0].startswith(\"h\"):\n            layer_number = int(variable_name_parts[0][1:])\n            target_dict = params[\"blocks\"][layer_number]\n\n        # Recursively access or create nested dictionaries\n        for key in variable_name_parts[1:-1]:\n            target_dict = target_dict.setdefault(key, {})\n\n        # Assign the variable array to the last key\n        last_key = variable_name_parts[-1]\n        target_dict[last_key] = variable_array\n\n    return params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:56.240860Z","iopub.execute_input":"2025-10-15T21:16:56.241126Z","iopub.status.idle":"2025-10-15T21:16:56.253519Z","shell.execute_reply.started":"2025-10-15T21:16:56.241107Z","shell.execute_reply":"2025-10-15T21:16:56.252724Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"BASE_CONFIG = {\n    'vocab_size': 50257,\n    'context_length': 1024,\n    'drop_rate': 0.0,\n    'qkv_bias': True\n}\nmodel_configs = {\n    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n}\nCHOOSE_MODEL = 'gpt2-medium (355M)'\nBASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n\nmodel_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\nsettings, params = download_and_load_gpt2(\n    model_size=model_size, \n    models_dir=\"gpt2\"\n )\nmodel = GPTModel(BASE_CONFIG)\nload_weights_into_gpt(model, params)\nmodel.eval();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:16:56.470870Z","iopub.execute_input":"2025-10-15T21:16:56.471511Z","iopub.status.idle":"2025-10-15T21:17:05.228303Z","shell.execute_reply.started":"2025-10-15T21:16:56.471487Z","shell.execute_reply":"2025-10-15T21:17:05.227505Z"}},"outputs":[{"name":"stdout","text":"File already exists and is up-to-date: gpt2/355M/checkpoint\nFile already exists and is up-to-date: gpt2/355M/encoder.json\nFile already exists and is up-to-date: gpt2/355M/hparams.json\nFile already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\nFile already exists and is up-to-date: gpt2/355M/model.ckpt.index\nFile already exists and is up-to-date: gpt2/355M/model.ckpt.meta\nFile already exists and is up-to-date: gpt2/355M/vocab.bpe\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"torch.manual_seed(123)\ninput_text = format_input(val_data[0])\nprint(input_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:05.229337Z","iopub.execute_input":"2025-10-15T21:17:05.229597Z","iopub.status.idle":"2025-10-15T21:17:05.235067Z","shell.execute_reply.started":"2025-10-15T21:17:05.229572Z","shell.execute_reply":"2025-10-15T21:17:05.234461Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"def text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special={'<|enodoftext|>'})\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n    return encoded_tensor\n    \ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0)\n    return tokenizer.decode(flat.tolist())\n\ndef generate(model, idx, max_new_tokens, context_size,\n            temperature=0.0, top_k=None, eos_id=None):\n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -context_size:]\n        with torch.no_grad():\n            logits = model(idx_cond)\n        logits = logits[:, -1, :]\n        if top_k is not None:\n            top_logits, _ = torch.topk(logits, top_k)\n            min_val = top_logits[:, -1]\n            logits = torch.where(\n                logits < min_val,\n                torch.tensor(float('-inf')).to(logits.device),\n                logits\n            )\n        if temperature > 0.0:\n            logits = logits / temperature\n            probs = torch.softmax(logits, dim=-1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n        else:\n            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n        if idx_next == eos_id:\n            break\n        idx = torch.cat((idx, idx_next), dim=1)\n    return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:07.709247Z","iopub.execute_input":"2025-10-15T21:17:07.709508Z","iopub.status.idle":"2025-10-15T21:17:07.716207Z","shell.execute_reply.started":"2025-10-15T21:17:07.709489Z","shell.execute_reply":"2025-10-15T21:17:07.715582Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"token_ids = generate(\n    model =  model,\n    idx = text_to_token_ids(input_text, tokenizer),\n    max_new_tokens = 35,\n    context_size = BASE_CONFIG['context_length'],\n    eos_id=50256\n)\ngenerated_text = token_ids_to_text(token_ids, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:09.421411Z","iopub.execute_input":"2025-10-15T21:17:09.422127Z","iopub.status.idle":"2025-10-15T21:17:23.113122Z","shell.execute_reply.started":"2025-10-15T21:17:09.422101Z","shell.execute_reply":"2025-10-15T21:17:23.112429Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"print('Input text:', input_text)\nprint('\\n\\nGenerated text:', generated_text)\nresponse_text = generated_text[len(input_text):].strip()\nprint('\\n\\nResponse\\n',response_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:23.114506Z","iopub.execute_input":"2025-10-15T21:17:23.114810Z","iopub.status.idle":"2025-10-15T21:17:23.119694Z","shell.execute_reply.started":"2025-10-15T21:17:23.114786Z","shell.execute_reply":"2025-10-15T21:17:23.119056Z"}},"outputs":[{"name":"stdout","text":"Input text: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\n\n\nGenerated text: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\n\n### Response:\n\nThe chef cooks the meal every day.\n\n### Instruction:\n\nConvert the active sentence to passive: 'The chef cooks the\n\n\nResponse\n ### Response:\n\nThe chef cooks the meal every day.\n\n### Instruction:\n\nConvert the active sentence to passive: 'The chef cooks the\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"def calc_loss_batch(input_batch, target_batch, model, device):\n    input_batch = input_batch.to(device)\n    target_batch = target_batch.to(device)\n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(\n        logits.flatten(0, 1), target_batch.flatten()\n    )\n    return loss\n\ndef calc_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0\n    if len(data_loader) == 0:\n        return float('nan')\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        num_batches = min(num_batches, len(data_loader))\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num_batches:\n            loss = calc_loss_batch(\n                input_batch, target_batch, model, device\n            )\n            total_loss += loss.item()\n        else:\n            break\n    return total_loss / num_batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:23.120593Z","iopub.execute_input":"2025-10-15T21:17:23.120882Z","iopub.status.idle":"2025-10-15T21:17:23.136168Z","shell.execute_reply.started":"2025-10-15T21:17:23.120865Z","shell.execute_reply":"2025-10-15T21:17:23.135550Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"def evaluate_model(model, train_laoder, val_loader, device, eval_iter):\n    model.eval()\n    with torch.no_grad():\n        train_loss = calc_loss_loader(\n            train_loader, model, device, num_batches = eval_iter\n        )\n        val_loss = calc_loss_loader(\n            val_loader, model, device, num_batches = eval_iter\n        )\n    model.train()\n    return train_loss, val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:23.137637Z","iopub.execute_input":"2025-10-15T21:17:23.137896Z","iopub.status.idle":"2025-10-15T21:17:23.154356Z","shell.execute_reply.started":"2025-10-15T21:17:23.137881Z","shell.execute_reply":"2025-10-15T21:17:23.153780Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"def generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_emb.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text_simple(\n            model = model, idx = encoded,\n            max_new_tokens = 50, context_size=context_size\n        )\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(decoded_text.replace('\\n', ' '))\n    model.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:23.154948Z","iopub.execute_input":"2025-10-15T21:17:23.155150Z","iopub.status.idle":"2025-10-15T21:17:23.170435Z","shell.execute_reply.started":"2025-10-15T21:17:23.155135Z","shell.execute_reply":"2025-10-15T21:17:23.169738Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"def train_model_simple(model, train_loader, val_loader, optimizer,\n                      device, num_epochs, eval_freq, eval_iter,\n                      start_context, tokenizer):\n    train_losses, val_losses, track_tokens_seen = [], [], []\n    tokens_seen, global_step = 0, -1\n    \n    for epoch in range(num_epochs):\n        model.train()\n        for input_batch, target_batch in train_loader:\n            optimizer.zero_grad()\n            loss = calc_loss_batch(\n                input_batch, target_batch, model, device\n            )\n            loss.backward()\n            optimizer.step()\n            tokens_seen += input_batch.numel()\n            global_step += 1\n            if global_step % eval_freq == 0:\n                train_loss, val_loss = evaluate_model(\n                    model, train_loader, val_loader, device, eval_iter\n                )\n                train_losses.append(train_loss)\n                val_losses.append(val_loss)\n                track_tokens_seen.append(tokens_seen)\n                print(f'Ep {epoch+1} (Step {global_step:06d}):'\n                     f'Train loss {train_loss:.3f},'\n                     f'Val loss {val_loss:.3f}'\n                )\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n    return train_losses, val_losses, track_tokens_seen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:23.171100Z","iopub.execute_input":"2025-10-15T21:17:23.171287Z","iopub.status.idle":"2025-10-15T21:17:23.188251Z","shell.execute_reply.started":"2025-10-15T21:17:23.171274Z","shell.execute_reply":"2025-10-15T21:17:23.187544Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"model.to(device)\ntorch.manual_seed(123)\n\nwith torch.no_grad():\n    train_loss = calc_loss_loader(\n        train_loader, model, device, num_batches=5\n    )\n    val_loss = calc_loss_loader(\n        val_loader, model, device, num_batches=5\n    )\nprint(\"Training loss:\", train_loss)\nprint(\"Validation loss:\", val_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:23.188953Z","iopub.execute_input":"2025-10-15T21:17:23.189134Z","iopub.status.idle":"2025-10-15T21:17:24.645056Z","shell.execute_reply.started":"2025-10-15T21:17:23.189121Z","shell.execute_reply":"2025-10-15T21:17:24.644369Z"}},"outputs":[{"name":"stdout","text":"Training loss: 3.82590970993042\nValidation loss: 3.797519254684448\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"import time\n\nstart_time = time.time()\ntorch.manual_seed(123)\noptimizer = torch.optim.AdamW(\n    model.parameters(), lr=0.00005, weight_decay=0.1\n)\nnum_epochs = 2\n\ntrain_losses, val_losses, tokens_seen = train_model_simple(\n    model, train_loader, val_loader, optimizer, device,\n    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n    start_context=format_input(val_data[0]), tokenizer=tokenizer\n )\nend_time = time.time()\nexecution_time_minutes = (end_time - start_time) / 60\nprint(f\"Training completed in {execution_time_minutes:.2f} minutes.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:17:31.981700Z","iopub.execute_input":"2025-10-15T21:17:31.982267Z","iopub.status.idle":"2025-10-15T21:19:24.281246Z","shell.execute_reply.started":"2025-10-15T21:17:31.982247Z","shell.execute_reply":"2025-10-15T21:19:24.280491Z"}},"outputs":[{"name":"stdout","text":"Ep 1 (Step 000000):Train loss 2.637,Val loss 2.621\nEp 1 (Step 000005):Train loss 1.083,Val loss 1.107\nEp 1 (Step 000010):Train loss 0.916,Val loss 0.930\nEp 1 (Step 000015):Train loss 0.829,Val loss 0.926\nEp 1 (Step 000020):Train loss 0.772,Val loss 0.829\nEp 1 (Step 000025):Train loss 0.753,Val loss 0.893\nEp 1 (Step 000030):Train loss 0.709,Val loss 0.805\nEp 1 (Step 000035):Train loss 0.750,Val loss 0.838\nEp 1 (Step 000040):Train loss 0.667,Val loss 0.799\nEp 1 (Step 000045):Train loss 0.765,Val loss 0.729\nEp 1 (Step 000050):Train loss 0.696,Val loss 0.743\nEp 1 (Step 000055):Train loss 0.604,Val loss 0.744\nEp 1 (Step 000060):Train loss 0.655,Val loss 0.746\nEp 1 (Step 000065):Train loss 0.662,Val loss 0.718\nEp 1 (Step 000070):Train loss 0.542,Val loss 0.710\nEp 1 (Step 000075):Train loss 0.559,Val loss 0.734\nEp 1 (Step 000080):Train loss 0.669,Val loss 0.737\nEp 1 (Step 000085):Train loss 0.576,Val loss 0.724\nEp 1 (Step 000090):Train loss 0.533,Val loss 0.662\nEp 1 (Step 000095):Train loss 0.624,Val loss 0.722\nEp 1 (Step 000100):Train loss 0.550,Val loss 0.658\nEp 1 (Step 000105):Train loss 0.428,Val loss 0.603\nEp 1 (Step 000110):Train loss 0.522,Val loss 0.684\nEp 1 (Step 000115):Train loss 0.448,Val loss 0.629\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\nEp 2 (Step 000120):Train loss 0.501,Val loss 0.643\nEp 2 (Step 000125):Train loss 0.460,Val loss 0.663\nEp 2 (Step 000130):Train loss 0.453,Val loss 0.665\nEp 2 (Step 000135):Train loss 0.471,Val loss 0.627\nEp 2 (Step 000140):Train loss 0.453,Val loss 0.710\nEp 2 (Step 000145):Train loss 0.458,Val loss 0.731\nEp 2 (Step 000150):Train loss 0.376,Val loss 0.661\nEp 2 (Step 000155):Train loss 0.439,Val loss 0.649\nEp 2 (Step 000160):Train loss 0.442,Val loss 0.670\nEp 2 (Step 000165):Train loss 0.352,Val loss 0.675\nEp 2 (Step 000170):Train loss 0.414,Val loss 0.677\nEp 2 (Step 000175):Train loss 0.399,Val loss 0.651\nEp 2 (Step 000180):Train loss 0.388,Val loss 0.693\nEp 2 (Step 000185):Train loss 0.382,Val loss 0.671\nEp 2 (Step 000190):Train loss 0.383,Val loss 0.649\nEp 2 (Step 000195):Train loss 0.401,Val loss 0.640\nEp 2 (Step 000200):Train loss 0.350,Val loss 0.592\nEp 2 (Step 000205):Train loss 0.363,Val loss 0.647\nEp 2 (Step 000210):Train loss 0.348,Val loss 0.626\nEp 2 (Step 000215):Train loss 0.309,Val loss 0.644\nEp 2 (Step 000220):Train loss 0.321,Val loss 0.621\nEp 2 (Step 000225):Train loss 0.304,Val loss 0.599\nEp 2 (Step 000230):Train loss 0.343,Val loss 0.654\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a simile. \nTraining completed in 1.87 minutes.\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\ndef plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n    fig, ax1 = plt.subplots(figsize=(5, 3))\n    ax1.plot(epochs_seen, train_losses, label='Training loss')\n    ax1.plot(\n        epochs_seen, val_losses, linestyle='-.', label='Validation loss'\n    )\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Loss')\n    ax1.legend(loc='upper right')\n    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n    ax2 = ax1.twiny()\n    ax2.plot(tokens_seen, train_losses, alpha=0)\n    ax2.set_xlabel('Tokens seen')\n    fig.tight_layout()\n    plt.show()\n\nepochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\nplot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:19:26.974277Z","iopub.execute_input":"2025-10-15T21:19:26.975003Z","iopub.status.idle":"2025-10-15T21:19:27.321466Z","shell.execute_reply.started":"2025-10-15T21:19:26.974981Z","shell.execute_reply":"2025-10-15T21:19:27.320769Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 500x300 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"torch.manual_seed(123)\n\nfor entry in test_data[:3]:\n    input_text = format_input(entry)\n    token_ids = generate(\n        model = model,\n        idx = text_to_token_ids(input_text, tokenizer).to(device),\n        max_new_tokens = 256,\n        context_size = BASE_CONFIG['context_length'],\n        eos_id=50256\n    )\n    generated_text = token_ids_to_text(token_ids, tokenizer)\n    response_text = (\n        generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n    )\n    print(input_text)\n    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n    print(\"-------------------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:19:46.626023Z","iopub.execute_input":"2025-10-15T21:19:46.626323Z","iopub.status.idle":"2025-10-15T21:19:48.224460Z","shell.execute_reply.started":"2025-10-15T21:19:46.626297Z","shell.execute_reply":"2025-10-15T21:19:48.223844Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nRewrite the sentence using a simile.\n\n### Input:\nThe car is very fast.\n\nCorrect response:\n>> The car is as fast as lightning.\n\nModel response:\n>> The car is as fast as a cheetah.\n-------------------------------------\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nWhat type of cloud is typically associated with thunderstorms?\n\nCorrect response:\n>> The type of cloud typically associated with thunderstorms is cumulonimbus.\n\nModel response:\n>> The type of cloud associated with thunderstorms is a cumulus.\n-------------------------------------\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nName the author of 'Pride and Prejudice'.\n\nCorrect response:\n>> Jane Austen.\n\nModel response:\n>> The author of 'Pride and Prejudice' is Jane Austen.\n-------------------------------------\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"!uv pip install tqdm>=4.66 tensorflow>=2.15.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:19:51.718322Z","iopub.execute_input":"2025-10-15T21:19:51.718897Z","iopub.status.idle":"2025-10-15T21:19:52.057812Z","shell.execute_reply.started":"2025-10-15T21:19:51.718873Z","shell.execute_reply":"2025-10-15T21:19:52.056805Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 133ms\u001b[0m\u001b[0m\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n    input_text = format_input(entry)\n    token_ids = generate(\n        model=model,\n        idx=text_to_token_ids(input_text, tokenizer).to(device),\n        max_new_tokens=256,\n        context_size=BASE_CONFIG[\"context_length\"],\n        eos_id=50256\n    )\n    generated_text = token_ids_to_text(token_ids, tokenizer)\n    response_text = (\n        generated_text[len(input_text):]\n        .replace(\"### Response:\", \"\").strip()\n    )\n    test_data[i][\"model_response\"] = response_text\n\nwith open('instruction-data-with-response.json', 'w') as file:\n    json.dump(test_data, file, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:19:54.162690Z","iopub.execute_input":"2025-10-15T21:19:54.163034Z","iopub.status.idle":"2025-10-15T21:20:48.108859Z","shell.execute_reply.started":"2025-10-15T21:19:54.163008Z","shell.execute_reply":"2025-10-15T21:20:48.108025Z"}},"outputs":[{"name":"stderr","text":"100%|| 110/110 [00:53<00:00,  2.04it/s]\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"print(test_data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T21:21:04.586121Z","iopub.execute_input":"2025-10-15T21:21:04.586685Z","iopub.status.idle":"2025-10-15T21:21:04.590704Z","shell.execute_reply.started":"2025-10-15T21:21:04.586663Z","shell.execute_reply":"2025-10-15T21:21:04.590085Z"}},"outputs":[{"name":"stdout","text":"{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n","output_type":"stream"}],"execution_count":79},{"cell_type":"raw","source":"import re\n\nfile_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"  \n\ntorch.save(model.state_dict(), file_name)\nprint(f\"Model saved as {file_name}\")","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}